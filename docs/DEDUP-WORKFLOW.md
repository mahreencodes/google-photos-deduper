# Dedup Workflow & Architecture ðŸ”

This document explains how Google Photos Deduper identifies duplicate images, how the chunked processing works, and how images are stored.

## High-level Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Google Photos Deduper                        â”‚
â”‚                                                                  â”‚
â”‚  1. Fetch Media Items                                            â”‚
â”‚     â””â”€> Google Photos API â†’ MongoDB (metadata storage)         â”‚
â”‚                                                                  â”‚
â”‚  2. Download Images (optional, per chunk if chunked)            â”‚
â”‚     â””â”€> Google Photos API â†’ Local filesystem                    â”‚
â”‚                                                                  â”‚
â”‚  3. Generate Embeddings                                          â”‚
â”‚     â””â”€> MediaPipe ImageEmbedder (MobileNet V3)                  â”‚
â”‚         â†’ Fixed-length vector embeddings (L2-normalized)        â”‚
â”‚                                                                  â”‚
â”‚  4. Compute Similarities                                        â”‚
â”‚     â””â”€> Cosine similarity between all pairs                      â”‚
â”‚         â†’ Similarity map (id â†’ id â†’ score)                      â”‚
â”‚                                                                  â”‚
â”‚  5. Cluster Duplicates                                           â”‚
â”‚     â””â”€> Connected components (Union-Find)                      â”‚
â”‚         â†’ Groups of similar images                              â”‚
â”‚                                                                  â”‚
â”‚  6. Select Originals                                            â”‚
â”‚     â””â”€> Largest dimensions per group â†’ Original candidate       â”‚
â”‚                                                                  â”‚
â”‚  7. User Review & Deletion                                       â”‚
â”‚     â””â”€> UI presents groups â†’ Chrome extension deletes           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Detailed Workflow

### Step 1: Fetch Media Items
```
Google Photos API
      â”‚
      â”œâ”€> List all media items (paginated)
      â”‚
      â””â”€> Store metadata in MongoDB
          â”œâ”€> Media item ID
          â”œâ”€> Filename
          â”œâ”€> Dimensions (width Ã— height)
          â”œâ”€> Base URL (for downloading)
          â””â”€> Other metadata
```

### Step 2: Image Download & Storage

**Non-chunked mode:**
```
For each media item:
  â”œâ”€> Download image (250Ã—250px thumbnail by default)
  â”œâ”€> Store to: {IMAGE_STORE_PATH}/{media_item_id}-{resolution}.jpg
  â””â”€> Set storageFilename on media item
```

**Chunked mode:**
```
For each chunk:
  â”œâ”€> Create temp directory: {TEMP_PATH}/embeddings-{task_id}/chunk-{N}-images/
  â”œâ”€> Download images for chunk only
  â”œâ”€> Compute embeddings
  â”œâ”€> Save embeddings to disk: chunk-{N}-embeddings.npy
  â”œâ”€> Save IDs mapping: chunk-{N}-ids.json
  â””â”€> Delete images (keep embeddings)
```

### Step 3: Embedding Generation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MediaPipe ImageEmbedder (MobileNet V3 Large)                â”‚
â”‚                                                               â”‚
â”‚  Input: Image file (JPEG)                                    â”‚
â”‚    â”‚                                                          â”‚
â”‚    â”œâ”€> Preprocessing                                         â”‚
â”‚    â”‚   â””â”€> Resize, normalize                                 â”‚
â”‚    â”‚                                                          â”‚
â”‚    â”œâ”€> MobileNet V3 Feature Extraction                       â”‚
â”‚    â”‚   â””â”€> Deep convolutional network                        â”‚
â”‚    â”‚                                                          â”‚
â”‚    â””â”€> Output: 1024-dimensional vector                       â”‚
â”‚        â””â”€> L2-normalized (unit vector)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Memory Optimization:
  - Process images in batches of 32
  - Explicitly free image memory after embedding
  - Use memory-mapped arrays for large embeddings (chunked mode)
```

### Step 4: Similarity Computation

**Non-chunked mode:**
```
All embeddings in memory (torch.Tensor)
      â”‚
      â”œâ”€> Compute cosine similarity matrix
      â”‚   â””â”€> cos_sim = embeddings @ embeddings.T
      â”‚       (since embeddings are L2-normalized)
      â”‚
      â””â”€> Extract pairs above threshold (â‰¥0.99 default)
          â””â”€> Similarity map: {id1: {id2: score, ...}, ...}
```

**Chunked mode (optimized):**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Chunked Pairwise Comparison                                â”‚
â”‚                                                              â”‚
â”‚  Chunk 0 â”€â”€â”                                                â”‚
â”‚  Chunk 1 â”€â”€â”¤                                                â”‚
â”‚  Chunk 2 â”€â”€â”¼â”€â”€> Compare all chunk pairs (i, j) where jâ‰¥i   â”‚
â”‚  Chunk 3 â”€â”€â”¤     â””â”€> Vectorized: emb_i @ emb_j.T          â”‚
â”‚  ...       â”˜     â””â”€> Use numpy.where() for threshold      â”‚
â”‚                     â””â”€> Memory-mapped arrays (mmap_mode='r')â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Example with 3 chunks:
  Comparisons: (0,0), (0,1), (0,2), (1,1), (1,2), (2,2)
  Total: 6 comparisons (n*(n+1)/2 for n=3)
```

### Step 5: Clustering (Group Detection)

```
Similarity Map (id â†’ id â†’ score)
      â”‚
      â”œâ”€> Union-Find (Disjoint Set Union)
      â”‚   â””â”€> Connect all pairs with similarity â‰¥ threshold
      â”‚
      â””â”€> Connected Components
          â””â”€> Each component = one duplicate group

Example:
  Similarity pairs: (A,B), (B,C), (D,E)
  Groups: [A, B, C], [D, E]
```

### Step 6: Original Selection

```
For each group:
  â”œâ”€> Calculate dimensions for each image
  â”‚   â””â”€> width Ã— height (pixels)
  â”‚
  â””â”€> Select image with largest dimensions
      â””â”€> Marked as "original" (others are duplicates)
```

## Chunked Processing Deep Dive

### Why Chunking?

For large libraries (10,000+ images), processing everything at once can:
- **Memory**: Require 10GB+ RAM for embeddings alone
- **Disk**: Store thousands of images simultaneously
- **Time**: Long-running processes risk interruption

### Chunked Processing Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 1: Chunk Processing                                   â”‚
â”‚                                                               â”‚
â”‚  Media Items [1..N]                                           â”‚
â”‚      â”‚                                                        â”‚
â”‚      â”œâ”€> Split into chunks of size `chunk_size` (default 500)â”‚
â”‚      â”‚                                                        â”‚
â”‚      Chunk 0: [1..500]    â”€â”€â”                                â”‚
â”‚      Chunk 1: [501..1000] â”€â”€â”¤                                â”‚
â”‚      Chunk 2: [1001..1500] â”€â”€â”¼â”€â”€> For each chunk:            â”‚
â”‚      ...                      â”‚   â”œâ”€> Download images        â”‚
â”‚                               â”‚   â”œâ”€> Compute embeddings     â”‚
â”‚                               â”‚   â”œâ”€> Save to disk (.npy)   â”‚
â”‚                               â”‚   â””â”€> Delete images          â”‚
â”‚                               â”˜                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 2: Cross-Chunk Comparison                             â”‚
â”‚                                                               â”‚
â”‚  Load embeddings from disk (memory-mapped)                    â”‚
â”‚      â”‚                                                        â”‚
â”‚      â”œâ”€> Compare chunk pairs (i, j) where j â‰¥ i              â”‚
â”‚      â”‚   â””â”€> Vectorized cosine similarity                    â”‚
â”‚      â”‚       â””â”€> emb_i_norm @ emb_j_norm.T                  â”‚
â”‚      â”‚                                                        â”‚
â”‚      â””â”€> Build similarity map incrementally                   â”‚
â”‚          â””â”€> Only pairs above threshold stored               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Memory Benefits:
  - Peak memory: O(chunk_size Ã— embedding_dim) instead of O(N Ã— embedding_dim)
  - Example: 10,000 images, 500 per chunk
    - Non-chunked: ~40MB embeddings in memory
    - Chunked: ~2MB embeddings in memory (20Ã— reduction)
```

### Performance Optimizations

1. **Vectorized Operations**: Use numpy matrix multiplication instead of nested loops
2. **Memory Mapping**: Load embeddings with `mmap_mode='r'` to avoid full memory load
3. **Batch Processing**: Process embeddings in batches during generation
4. **Early Cleanup**: Delete images immediately after embedding computation
5. **Progress Tracking**: Log chunk progress for user visibility

## Image Storage Options

### Resolution Control
- **Default**: 250Ã—250px thumbnails (fast, low bandwidth)
- **Original**: Full resolution (slower, higher quality embeddings)

### Storage Location
- **Default**: `{IMAGE_STORE_PATH}` (configurable via env var)
- **Custom**: `image_store_path` task option (e.g., external drive)

### File Naming
```
{media_item_id}-{resolution}.jpg    # Thumbnail
{media_item_id}-original.jpg         # Original (if download_original=true)
```

## Embeddings & Matching Algorithm

### Embedding Model
- **Model**: MediaPipe ImageEmbedder (MobileNet V3 Large)
- **Output Dimension**: 1024
- **Normalization**: L2-normalized (unit vectors)
- **Download**: Auto-downloads from Google Cloud Storage if missing

### Similarity Metric
```
Cosine Similarity = (A Â· B) / (||A|| Ã— ||B||)

Since embeddings are L2-normalized:
  Cosine Similarity = A Â· B  (dot product)

Range: [-1, 1]
  - 1.0 = Identical
  - 0.99 = Very similar (default threshold)
  - 0.0 = Unrelated
```

### Clustering Algorithm

**Non-chunked**: Fast community detection
- Uses top-k similarity search
- Extracts communities with min_community_size=2
- Removes overlapping communities

**Chunked**: Union-Find (Disjoint Set Union)
```
Algorithm:
  1. Initialize: parent[i] = i for all images
  2. For each pair (i, j) with similarity â‰¥ threshold:
       union(i, j)
  3. Find connected components
  4. Filter groups with size â‰¥ 2
```

## Error Cases & Re-authentication

### Insufficient Scopes
```
Error: "insufficient_scopes"
  â”œâ”€> Task returns structured error
  â”œâ”€> Server exposes /api/credentials endpoint
  â””â”€> UI shows Credentials Diagnostics panel
      â””â”€> Guides user to re-authorize
```

### Rate Limiting
- **429 Errors**: Automatic retry with exponential backoff
- **Daily Quota**: Task fails gracefully with clear message

### Image Download Failures
- **Retry Logic**: 3 attempts with configurable delays
- **Skip on Failure**: Continue processing other images

## Performance Characteristics

### Time Complexity
- **Embedding Generation**: O(N) where N = number of images
- **Similarity Computation**: O(NÂ²) in worst case, but optimized with:
  - Chunking: O((N/C)Â² Ã— CÂ²) = O(NÂ²) but with lower constant factors
  - Top-k pruning: Reduces comparisons
- **Clustering**: O(N Ã— Î±(N)) where Î± is inverse Ackermann (Union-Find)

### Space Complexity
- **Non-chunked**: O(N Ã— D) where D = embedding dimension (1024)
- **Chunked**: O(C Ã— D) where C = chunk_size (typically 500)

### Typical Performance
- **Small library** (<1,000 images): ~2-5 minutes
- **Medium library** (1,000-10,000 images): ~10-30 minutes
- **Large library** (10,000+ images): ~1-3 hours (chunked mode recommended)

---

## Future Enhancements

- **Persistent Embeddings**: Option to save embeddings for resume/audit
- **Incremental Processing**: Only process new images since last run
- **GPU Acceleration**: Optional GPU support for faster embedding computation
- **Parallel Chunk Processing**: Process multiple chunks concurrently
